{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8d32e7",
   "metadata": {},
   "source": [
    "# GAN architectures\n",
    "\n",
    "<img src=\"images/GANsnRoses.png\" width=\"150pt\"/>\n",
    "\n",
    "Many GANs in our armory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45e361",
   "metadata": {},
   "source": [
    "## [Progressive GAN](https://arxiv.org/abs/1710.10196) (Oct 2017)\n",
    "\n",
    "Challange: generate __high-resolution high-detail__ pictures.\n",
    "\n",
    "### Progressively growing the resolution\n",
    "\n",
    "<img src=\"images/ProGAN_grow.webp\" width=\"600pt\"/>\n",
    "\n",
    "### Fading between resolutions\n",
    "\n",
    "<img src=\"images/ProGAN_blend.png\" width=\"600pt\"/>\n",
    "\n",
    "### Tricks\n",
    "\n",
    "- __Increased variation__ with batch statistics:  \n",
    "  __standard-deviation layer__ concatenated at the end of the discriminator.\n",
    "- __Controlled weights__ with run-time weight normalization using [He's initialization](https://arxiv.org/abs/1502.01852).\n",
    "- __Controlled featurte maps__ with featrure map normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4f47a",
   "metadata": {},
   "source": [
    "## [Style GAN](https://arxiv.org/abs/1812.04948) (Dec 2018)\n",
    "\n",
    "This paper proposed heavy changes on the generator part.\n",
    "\n",
    "<img src=\"images/StyleGAN.png\" width=\"500pt\"/>\n",
    "\n",
    "### No input layer, latents \"from the side\"\n",
    "\n",
    "- __No input layer__ for the noise;\n",
    "- a __learned constant__ instead.\n",
    "- Latent variables $w$ __affinely transformed__;\n",
    "- noise $\\sigma$ __scale trasformed__;\n",
    "- both $w$ and $\\sigma$ inserted __from the side__;\n",
    "- generator controlled at __different resolutions__.\n",
    "\n",
    "### Mapping framework from latents $z$ to styles $w$\n",
    "\n",
    "Latents $z$ are non-linearly mapped to the latent space $\\mathcal{W}$.\n",
    "\n",
    "$\\mathcal{W}$ represents high-level characteristics.\n",
    "\n",
    "In $\\mathcal{W}$ the variables are more disentagled than $\\mathcal{Z}$ (shown by separability measure).\n",
    "\n",
    "### Adaptive Instance Normalization\n",
    "\n",
    "Batch normalization reduces the variability, instance-normalization is better.\n",
    "\n",
    "These are the normalization definitions:\n",
    "\n",
    "$$\\large\n",
    "BN(x) = \\alpha \\frac{x - \\mu(x)}{\\sigma(x)} + \\beta\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "IN(x_i) = \\alpha \\frac{x_i - \\mu(x_i)}{\\sigma(x_i)} + \\beta\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "AdaIN(x_i, y) = y_{s,i} \\frac{x_i - \\mu(x_i)}{\\sigma(x_i)} + y_{b,i}\n",
    "$$\n",
    "\n",
    "where $y$ is the style ($w$ affinely transformed), __no more trained parameters__.\n",
    "\n",
    "### Mixed regularization\n",
    "\n",
    "Geneate __many $w$s__, feed them randomly at different resolutions.\n",
    "\n",
    "FID wrt the number of $w$s (FFHQ):\n",
    "\n",
    "Mixing regularization |   1   |   2   |   3   |   4\n",
    ":-------------------- | :---: | :---: | :---: | :---:\n",
    "0% | 4.42 | 8.22 | 12.88 | 17.41\n",
    "50% | 4.41 | 6.10 | 8.71 | 11.61\n",
    "90% | __4.40__ | __5.11__ | 6.88 | 9.03\n",
    "100% | 4.83 | 5.17 | __6.63__ | __8.40__\n",
    "\n",
    "### Results\n",
    "\n",
    "FID measure on different work steps (the lower the better):\n",
    "\n",
    "Method | CelebA-HQ | FFHQ\n",
    ":----- | :-------: | :--:\n",
    "  Baseline Progressive GAN | 7.79 | 8.04\n",
    "+ Tuning (incl. bilinear up/down) | 6.11 | 5.25\n",
    "+ Add mapping and styles | 5.34 | 4.85\n",
    "+ Remove traditional input | 5.07 | 4.88\n",
    "+ Add noise inputs | __5.06__ | 4.42\n",
    "+ Mixing regularization | 5.17 | __4.40__\n",
    "\n",
    "### Mixing styles\n",
    "\n",
    "<img src=\"images/StyleGAN_styles.png\" width=\"500pt\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a0176",
   "metadata": {},
   "source": [
    "## [Style GAN 2](https://arxiv.org/abs/1912.04958) (Dec 2019)\n",
    "\n",
    "Localized improvements to StyleGAN.\n",
    "\n",
    "## Normalization artifacts\n",
    "\n",
    "AdaIN normalization generates __droplet-like artifacts__.\n",
    "\n",
    "This is a generator attempt to __bypass the normalization using spikes__.\n",
    "\n",
    "<img src=\"images/StyleGAN2_droplets.png\" width=\"750pt\"/>\n",
    "\n",
    "Main change: __noise after normalization__ but __before modulation__.\n",
    "\n",
    "Secondary change: __mean normalization not needed__ anymore.\n",
    "\n",
    "<img src=\"images/StyleGAN2.png\" width=\"750pt\"/>\n",
    "\n",
    "Final step: weight (de)modulation.  \n",
    "Do not directly normalize/scale instances, __adjust convolution weights__ instead:\n",
    "\n",
    "$$\\large\n",
    "w'_{ijk} = s_i \\cdot w_{ijk}\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "w''_{ijk} = \\frac{w'_{ijk}}{\\sqrt{\\sum_{i,k}{w'_{ijk}}^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "## Better progressive growing\n",
    "\n",
    "Progressive growing generates artifacts:\n",
    "\n",
    "<img src=\"images/StyleGAN_issues.gif\" width=\"600pt\"/>\n",
    "\n",
    "These mitigated by revisited network architecture:\n",
    "\n",
    "<img src=\"images/StyleGAN_progressive.png\" width=\"600pt\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6cd97",
   "metadata": {},
   "source": [
    "## [Style GAN 2 ADA](https://arxiv.org/abs/2006.06676) (Jun 2020)\n",
    "\n",
    "Problem: with a small dataset __D memorizes the data__ (overfitting).\n",
    "\n",
    "Solution: __augment the dataset__.\n",
    "\n",
    "Problem: the __generator produces augmented images__ (\"leaking\" augmentations).\n",
    "\n",
    "Solution: __augment both reals and fakes__, this requires __differentiable augmentations__.\n",
    "\n",
    "<img src=\"images/StyleGAN2-ADA.png\" width=\"750pt\"/>\n",
    "\n",
    "## Leaking augmentations\n",
    "\n",
    "Depending on augmentation type and probability, it can leak or not:\n",
    "\n",
    "<img src=\"images/StyleGAN2-ADA_leaking.png\" width=\"750pt\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41b73b",
   "metadata": {},
   "source": [
    "## [Style GAN 3, Alias-Free GAN](https://arxiv.org/abs/2106.12423) (Oct 2021)\n",
    "\n",
    "### The problem\n",
    "\n",
    "> Textures used by the generator are not translation/rotation invatiant.\n",
    "\n",
    "<img src=\"images/StyleGAN3_alias01.gif\" width=\"750\"/>\n",
    "<img src=\"images/StyleGAN3_alias02.gif\" width=\"750\"/>\n",
    "\n",
    "Watch some videos [here](https://nvlabs.github.io/stylegan3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537357a",
   "metadata": {},
   "source": [
    "### Continuous signal interpretation (and bandlimit requirement)\n",
    "\n",
    "By Niquist-Shannon: \n",
    "\n",
    "> A signal can be fulluy restored sampling at 2 times its maximum frequency.\n",
    "\n",
    "Consider the image $Z$ as the continuos image signal $z$ multiplied with a sampling grid of Dirac deltas $III_s$.\n",
    "\n",
    "$$\\Large\n",
    "Z = z \\odot III_s\n",
    "$$\n",
    "\n",
    "The opposite direction obtained by convolution with the 2d sync function:\n",
    "\n",
    "$$\\Large\n",
    "z = Z * \\phi_s\n",
    "$$\n",
    "\n",
    "<img src=\"images/StyleGAN3_continuous.png\" width=\"600\"/>\n",
    "\n",
    "Continuous and equivalent discrete operators $f$ and $F$ are related with:\n",
    "\n",
    "$$\\Large\n",
    "f(z) = F(z \\odot III_s) * \\phi_s \\qquad F(Z) = f(Z * \\phi_s) \\odot III_s \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce1860",
   "metadata": {},
   "source": [
    "### Equivalence\n",
    "\n",
    "Given the input, __we wish equivalence under translation and rotation__.\n",
    "\n",
    "An operator $f$ is equivalent under a transformation $t$ if commutes: $t\\cdot f = f\\cdot t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129c936",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "- __Convolution__: \n",
    " - bandwidth requirements and translation equivalence by nature, \n",
    " - rotation invariance using 1x1 convolutions.\n",
    "- __Upsample/Downsample__:\n",
    " - translation/rotation invariant,\n",
    " - implemented as pad-convolve and convolve-drop.\n",
    "- __Nonlinearity__:\n",
    " - pointwise operations have translation/rotation invariance.\n",
    " - bandwidth limit managed by changing resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8205fcd",
   "metadata": {},
   "source": [
    "### Changed structure\n",
    "\n",
    "- Input 4x4x1024 substituted by fourier features (same sampling space but representation in 36x36x1024).\n",
    "- No noise input.\n",
    "- Fewer layers (14 VS 18).\n",
    "- Low-pass filtering with jinc (Sombrero).\n",
    "\n",
    "<img src=\"images/StyleGAN3.png\" width=\"600\"/>\n",
    "<center><a href=\"https://medium.com/@steinsfu/stylegan3-clearly-explained-793edbcc8048\">Steins</a></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
