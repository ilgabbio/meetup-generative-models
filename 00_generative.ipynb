{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48483c0",
   "metadata": {},
   "source": [
    "# Discriminative VS generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3aafc",
   "metadata": {},
   "source": [
    "## Latent variables\n",
    "\n",
    "Explain/discover structure in data:\n",
    "    \n",
    "- estimate the underlying pdf;\n",
    "- model the pdf as unobservable random variables $h$ inducing observable outcomes $x$.\n",
    "\n",
    "> The variables $h$ are the __hidden causes__ behind the outcome generation.\n",
    "\n",
    "Inference of the hidden variables $h$ given the outcome $x$, by chain rule the following are equivalent:\n",
    "\n",
    "$$\\large\n",
    "p(h|x)p(x) = p(x|h)p(h)\n",
    "$$\n",
    "\n",
    "This means that using $x$ we can discover $h$ directly estimating: $\\large p(h|x)p(x)$.\n",
    "\n",
    "But another possibility is to estimate $h$ maximizing the likelihood of data: $\\large p(x|h)$ or the posterior $\\large p(x|h)p(h)$.\n",
    "\n",
    "These two expressions can be represented as Bayesian networks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import graph\n",
    "\n",
    "base = \"h[style=filled,fillcolor=gray]\\n\"\n",
    "graph(f\"{base}x->h\", title=\"Direct modeling: $\\large arg\\max_hp(h|x)p(x)$\")\n",
    "graph(f\"{base}h->x\", title=\"A-posteriori estimation maximizing: $\\large arg\\max_hp(x|h)p(h)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a0df8",
   "metadata": {},
   "source": [
    "In the latter case no $p(x)$ must be estimated, generally being that pdf the intractable one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b32ad",
   "metadata": {},
   "source": [
    "## Direct $p(h|x)$ estimation: discriminative models\n",
    "\n",
    "Naive Bayes: $\\large p(h|x)=\\prod_i{p(h_i|x)}$\n",
    "\n",
    "We can estimate the (simpler) $p(h_i|x)$ (eg. in tabular form).\n",
    "\n",
    "Given an $x$, choose the combination of $h_i$ maximizing $p(h|x)$.\n",
    "\n",
    "Practical example: classification (only one $h_i$ to 1, the remaining to 0).\n",
    "\n",
    "__This approach allows discrimination only__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfde3f2",
   "metadata": {},
   "source": [
    "## Maximum likelihood $p(x|h)$ estimation: generative models\n",
    "\n",
    "PPCA: $\\large x = Wh + \\mu + \\sigma$  \n",
    "where $h \\sim \\mathcal{N}(\\cdot;I,0)$\n",
    "\n",
    "A stochastic recipe to compute $x$ given $h$ is defined by the model.\n",
    "\n",
    "__This approach allows both discrimination and generation__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
