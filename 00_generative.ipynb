{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48483c0",
   "metadata": {},
   "source": [
    "# Discriminative VS generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3aafc",
   "metadata": {},
   "source": [
    "## Latent variables\n",
    "\n",
    "Explain/discover structure in data:\n",
    "    \n",
    "- estimate the underlying pdf;\n",
    "- model the pdf as unobservable random variables $h$ inducing observable outcomes $x$.\n",
    "\n",
    "> The variables $h$ are the __hidden causes__ behind the outcome generation.\n",
    "\n",
    "Inference of the hidden variables $h$ given the outcome $x$, by chain rule the following are equivalent:\n",
    "\n",
    "$$\\large\n",
    "p(h|x)p(x) = p(x|h)p(h)\n",
    "$$\n",
    "\n",
    "This means that using $x$ we can discover $h$ directly estimating: $\\large p(h|x)p(x)$.\n",
    "\n",
    "But another possibility is to estimate $h$ maximizing the likelihood of data: $\\large p(x|h)$ or the posterior $\\large p(x|h)p(h)$.\n",
    "\n",
    "These two expressions can be represented as Bayesian networks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import graph\n",
    "\n",
    "base = \"h[style=filled,fillcolor=gray]\\n\"\n",
    "graph(f\"{base}x->h\", title=\"Direct modeling: $\\large arg\\max_hp(h|x)p(x)$\")\n",
    "graph(f\"{base}h->x\", title=\"A-posteriori estimation maximizing: $\\large arg\\max_hp(x|h)p(h)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a0df8",
   "metadata": {},
   "source": [
    "In the latter case no $p(x)$ must be estimated, generally being that pdf the intractable one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b32ad",
   "metadata": {},
   "source": [
    "## Direct $p(h|x)$ estimation: discriminative models\n",
    "\n",
    "Naive Bayes: $\\large p(h|x)=\\prod_i{p(h_i|x)}$\n",
    "\n",
    "We can estimate the (simpler) $p(h_i|x)$ (eg. in tabular form).\n",
    "\n",
    "Given an $x$, choose the combination of $h_i$ maximizing $p(h|x)$.\n",
    "\n",
    "Practical example: classification (only one $h_i$ to 1, the remaining to 0).\n",
    "\n",
    "__This approach allows discrimination only__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfde3f2",
   "metadata": {},
   "source": [
    "## Maximum likelihood $p(x|h)$ estimation: generative models\n",
    "\n",
    "PPCA: $\\large x = Wh + \\mu + \\sigma$  \n",
    "where $h \\sim \\mathcal{N}(\\cdot;I,0)$\n",
    "\n",
    "A stochastic recipe to compute $x$ given $h$ is defined by the model.\n",
    "\n",
    "__This approach allows both discrimination and generation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data (from https://github.com/daradecic/Python-Eigenfaces):\n",
    "faces = pd.read_csv('data/face_data.csv')\n",
    "faces = faces.drop('target',axis=1)\n",
    "faces = np.array(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_face(face):\n",
    "    plt.figure()\n",
    "    plt.imshow(face.reshape(64, 64), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "plot_face(faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Computing the PCA of images:\n",
    "pca = PCA(n_components=100).fit(faces)\n",
    "latent = pca.transform(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92424e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing a face:\n",
    "def reconstruct_face(latent):\n",
    "    return pca.inverse_transform(latent)\n",
    "\n",
    "def plot_reconstructed_face(latent):\n",
    "    plot_face(reconstruct_face(latent))\n",
    "\n",
    "plot_reconstructed_face(latent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import interact_vector\n",
    "\n",
    "# Synthesis of new faces:\n",
    "def plot_new_face(v):\n",
    "    # Mean and modified face:\n",
    "    n = latent.shape[1]\n",
    "    h = np.zeros((n,))\n",
    "    f_mean = reconstruct_face(h)\n",
    "    h[0:len(v)] = v\n",
    "    f_mod = reconstruct_face(h)\n",
    "    \n",
    "    # Plotting both:\n",
    "    _, axes = plt.subplots(1, 2, figsize=(8, 16))\n",
    "    fs = [f_mean,f_mod]\n",
    "    for i in range(2):\n",
    "        axes[i].imshow(fs[i].reshape(64, 64), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"v:\",h)\n",
    "\n",
    "# Interactive face reconstruction:\n",
    "interact_vector(\"v\", 10, plot_new_face, min=-10, max=10, step=1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
