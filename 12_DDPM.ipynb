{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8d267d",
   "metadata": {},
   "source": [
    "# GAN architectures\n",
    "\n",
    "<img src=\"images/GANsnRoses.png\" width=\"150pt\"/>\n",
    "\n",
    "Many GANs in our armory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a2351f",
   "metadata": {},
   "source": [
    "## [Denoising Diffusion Probabilistic Models (DDPMs)](https://arxiv.org/abs/2006.11239) (Jun 2020)\n",
    "\n",
    "Idea: __sampling a simple distribution__ (gaussian) and __moving on a path__ toward the data distribution. \n",
    "\n",
    "<img src=\"images/DDPM_path.png\" width=\"750pt\"/>\n",
    "\n",
    "Coinsider a DAE as a _denoising function_, imagine to iterate the process:\n",
    "\n",
    "<img src=\"images/DDPM.png\" width=\"750pt\"/>\n",
    "\n",
    "Consider the denoising process a Markov chain with:\n",
    "\n",
    "$$\\large\n",
    "p(x_{0..T}) = p(x_T)\\prod_{t=0}^T p(x_{t-1}|x_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\large\n",
    "p(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu(x_t,t), \\Sigma(x_t,t))\n",
    "$$\n",
    "\n",
    "The opposite (diffusion) process is:\n",
    "\n",
    "$$\\large\n",
    "p(x_{1..T}|x_0) = \\prod_{t=1}^T q(x_{t}|x_{t-1})\n",
    "$$\n",
    "\n",
    "where for small steps it is assumed that:\n",
    "\n",
    "$$\\large\n",
    "q(x_{t}|x_{t-1}) = \\mathcal{N}(x_{t}; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)\n",
    "$$\n",
    "\n",
    "For a variance schedule $\\beta_1, \\cdots, \\beta_T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3517b",
   "metadata": {},
   "source": [
    "### The loss\n",
    "\n",
    "Combination of forward and backward steps ($p$ and $q$) in __one denoising step is a VAE__.\n",
    "\n",
    "Objective, __maximization of the ELBO__:\n",
    "\n",
    "$$\\large\n",
    "\\mathcal{L} = \\mathbb{E}_q\\left[\\log p(x_T) + \\sum_{t\\geq1}\\log\\frac{p(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3199dac",
   "metadata": {},
   "source": [
    "### The architecture\n",
    "\n",
    "Based on a [PixelCNN++](https://arxiv.org/abs/1701.05517), that is a double-streamed U-Net:\n",
    "\n",
    "<img src=\"images/DDPM_arch.png\" width=\"750pt\"/>\n",
    "\n",
    "__Every time-step represents a single net forward pass.__\n",
    "\n",
    "(The time-step is encoded using a _transformer sinusoidal position encoding_.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a9d8a",
   "metadata": {},
   "source": [
    "### Some qualitative results\n",
    "\n",
    "Examples of denoising/diffusion:\n",
    "\n",
    "<img src=\"images/DDPM_examples.png\" width=\"750pt\"/>\n",
    "\n",
    "On the MNIST dataset:\n",
    "\n",
    "<img src=\"images/DDPM_mnist.gif\" width=\"500pt\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed44ca",
   "metadata": {},
   "source": [
    "## [Diffusion models Beat GANs](https://arxiv.org/abs/2105.05233) (11 May 2021)\n",
    "\n",
    "After many improvements to DDPM:\n",
    "\n",
    "<img src=\"images/DDPM2_examples.png\" width=\"750pt\"/>\n",
    "\n",
    "### List of main changes\n",
    "\n",
    "- conditional denoising:\n",
    " - classifier incorporated in the model;\n",
    " - gradient scaling to better guide to the required class;\n",
    "- AdaGN:\n",
    " - $AdaGN(h,y) = y_s GroupNorm(h) + y_b$;\n",
    " - $y = [y_s,y_s]$ as linear projection of $t$ and class embedding;\n",
    " - [group normalization](https://arxiv.org/abs/1803.08494) acts on __contiguous groups of channels__;\n",
    "- adaptive variance schedule via NN;\n",
    "- [Denoising Diffusion Implicit Models (DDIM)](https://arxiv.org/abs/2010.02502);\n",
    "- other ablations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935fb4b",
   "metadata": {},
   "source": [
    "# [Texture Generation with Neural Cellular Automata](https://arxiv.org/abs/2105.07299) (15 May 2021)\n",
    "\n",
    "As anticipated by [Alan Turing](http://www.marconlab.org/papers/turing.pdf),\n",
    "patterns emerge from [reaction diffusion systems](https://en.wikipedia.org/wiki/Reaction%E2%80%93diffusion_system).\n",
    "\n",
    "Consider the diffusion model PDE:\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\partial s}{\\partial t} = f(s,\\nabla_x(s),\\nabla^2_x(s))\n",
    "$$\n",
    "\n",
    "Consider encoding \n",
    "[Conway's game of life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life)\n",
    "like rules in $f$.\n",
    "\n",
    "Consider encoding this system in a deep neural network:\n",
    "\n",
    "<img src=\"images/NCA_arch.svg\" width=\"750pt\"/>\n",
    "\n",
    "where:\n",
    "\n",
    "- $I_3$ is the 3-channels image;\n",
    "- $K_x$ and $K_y$ are spatial derivative kernels (Sobel filters have been used);\n",
    "- $K_{lap}$ is a laplacian filter kernel;\n",
    "- the stochastic update allows to update stochastically the cells (breaking the all-in-one simmetry).\n",
    "\n",
    "We get [self organizing textures](https://distill.pub/selforg/2021/textures/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
